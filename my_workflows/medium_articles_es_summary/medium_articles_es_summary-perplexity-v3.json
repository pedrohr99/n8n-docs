{
  "name": "medium_articles_es_summary",
  "nodes": [
    {
      "parameters": {},
      "id": "37c82eb5-f4ad-49b9-b89f-53440ae630a1",
      "name": "When executed by another node",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "position": [
        -1056,
        128
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "url": "={{ 'https://r.jina.ai/http://' + $json['url'].replace('https://','').replace('http://','') }}",
        "options": {
          "redirect": {},
          "timeout": 15000
        }
      },
      "id": "099eea04-bdc4-4add-acbb-2d7960354425",
      "name": "Fetch Medium HTML",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -848,
        128
      ]
    },
    {
      "parameters": {
        "conditions": {
          "booleans": [
            {
              "value1": "={{$json.paywalled}}"
            }
          ]
        },
        "options": {}
      },
      "id": "923b768b-cec4-4381-a941-6f04cb4017d1",
      "name": "Member-only?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        0,
        128
      ]
    },
    {
      "parameters": {},
      "id": "2a572ccf-dbf8-4bef-8579-b1b3946b3936",
      "name": "Log (member-only)",
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [
        208,
        0
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "name": "title",
              "type": "string",
              "value": "={{$json.title}}"
            },
            {
              "name": "title_translate",
              "type": "string",
              "value": "Contenido solo para miembros"
            },
            {
              "name": "summary_translate",
              "type": "string",
              "value": "No se pudo acceder sin login."
            },
            {
              "name": "url",
              "type": "string",
              "value": "={{$json.url}}"
            }
          ]
        },
        "options": {}
      },
      "id": "edaeb9ed-5c98-4f22-a131-16376377c735",
      "name": "Shape Output (skip)",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        416,
        0
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {}
          ]
        },
        "options": {
          "timeout": 30000
        }
      },
      "id": "a95544f6-95b9-4d94-bd29-cd6d7aabe879",
      "name": "OpenAI Chat (JSON)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        208,
        240
      ]
    },
    {
      "parameters": {
        "jsCode": "const choice = $json.choices?.;\nconst content = choice?.message?.content || '{}';\nlet obj;\ntry { obj = JSON.parse(content); } catch(e) { obj = { title_translate: 'Error de parseo', summary_translate: 'Salida no válida' }; }\nreturn [{ json: { url: $json.url, title: $json.title, ...obj } }];"
      },
      "id": "6d9d09e0-3a0c-44ed-9cf1-97c030ee528f",
      "name": "Parse OpenAI JSON",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        416,
        240
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "name": "title",
              "type": "string",
              "value": "={{$json.title}}"
            },
            {
              "name": "title_translate",
              "type": "string",
              "value": "={{$json.title_translate}}"
            },
            {
              "name": "summary_translate",
              "type": "string",
              "value": "={{$json.summary_translate}}"
            },
            {
              "name": "url",
              "type": "string",
              "value": "={{$json.url}}"
            }
          ]
        },
        "options": {}
      },
      "id": "1a78dec2-98ac-4980-aacd-78e0b738cf09",
      "name": "Shape Output",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        608,
        240
      ]
    },
    {
      "parameters": {
        "jsCode": "const md = $json.data || '';\nconst m = md.match(/^#\\s+(.+?)\\s*$/m);\nconst title = m ? m[1].trim() : 'Sin título';\nlet content = md.replace(/^#\\s+.+$/m, '').trim().replace(/\\s+/g,' ');\nif (content.length > 8000) content = content.slice(0,8000) + '...';\nreturn [{ json: { url: $json.url, title, content, paywalled: false } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -640,
        128
      ],
      "id": "2aab6639-db99-464f-ba37-ea8a0a3c952d",
      "name": "Parse Reader Markdown"
    }
  ],
  "pinData": {
    "When executed by another node": [
      {
        "json": {
          "url": "https://medium.com/@mehulgupta_7991/meta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221"
        }
      }
    ],
    "Fetch Medium HTML": [
      {
        "json": {
          "data": "Title: Meta Dino-V3 : The ultimate Vision AI for every Image task\n\nURL Source: http://medium.com/@mehulgupta_7991/meta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221\n\nPublished Time: 2025-08-15T04:07:40Z\n\nMarkdown Content:\nMeta Dino-V3 : The ultimate Vision AI for every Image task | by Mehul Gupta | Data Science in Your Pocket | Aug, 2025 | Medium\n\n===============\n\n[Sitemap](http://medium.com/sitemap/sitemap.xml)\n\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcf5ffc30a221&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](http://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[](http://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\n\n[Write](http://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n\n[](http://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](http://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n![Image 12: Alberto Scocco](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)\n\n[Mastodon](https://me.dm/@mehulgupta_7991)\n\n[Data Science in Your Pocket ---------------------------](https://medium.com/data-science-in-your-pocket?source=post_page---publication_nav-60130df77e02-cf5ffc30a221---------------------------------------)\n\n·\n[Follow publication](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fdata-science-in-your-pocket&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&collection=Data+Science+in+Your+Pocket&collectionId=60130df77e02&source=post_page---publication_nav-60130df77e02-cf5ffc30a221---------------------publication_nav------------------)\n\n[![Image 13: Data Science in Your Pocket](https://miro.medium.com/v2/resize:fill:38:38/1*azLPGT6SA58kykLPlca3TQ.jpeg)](https://medium.com/data-science-in-your-pocket?source=post_page---post_publication_sidebar-60130df77e02-cf5ffc30a221---------------------------------------)\nWe are on Youtube: [https://www.youtube.com/channel/UCQoNosQTIxiMTL9C-gvFdjA](https://www.youtube.com/channel/UCQoNosQTIxiMTL9C-gvFdjA)\n\n[Follow publication](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fdata-science-in-your-pocket&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&collection=Data+Science+in+Your+Pocket&collectionId=60130df77e02&source=post_page---post_publication_sidebar-60130df77e02-cf5ffc30a221---------------------post_publication_sidebar------------------)\n\nTop highlight\n\nMeta Dino-V3 : The ultimate Vision AI for every Image task\n==========================================================\n\nHow to use Dino-V3 for free?\n----------------------------\n\n[![Image 14: Mehul Gupta](https://miro.medium.com/v2/resize:fill:32:32/1*vyvhK_h4zA05mg_Y-n2qBA.jpeg)](http://medium.com/@mehulgupta_7991?source=post_page---byline--cf5ffc30a221---------------------------------------)\n\n[Mehul Gupta](http://medium.com/@mehulgupta_7991?source=post_page---byline--cf5ffc30a221---------------------------------------)\n\nFollow\n\n6 min read\n\n·\n\nAug 15, 2025\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-in-your-pocket%2Fcf5ffc30a221&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&user=Mehul+Gupta&userId=d4ec90760d5b&source=---header_actions--cf5ffc30a221---------------------clap_footer------------------)\n\n115\n\n3\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcf5ffc30a221&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&source=---header_actions--cf5ffc30a221---------------------bookmark_footer------------------)\n\n[Listen](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Dcf5ffc30a221&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&source=---header_actions--cf5ffc30a221---------------------post_audio_button------------------)\n\nShare\n\nPress enter or click to view image in full size\n\n![Image 15](https://miro.medium.com/v2/resize:fit:700/0*NwmmTG0QgF2NhVP0)\n\nPhoto by [Hannah Pemberton](https://unsplash.com/@wandalust?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\nI’ve been following the DINO line of models for a while now. Mostly because they get at something a lot of vision models don’t even try: giving you _dense_ features without supervision.\n\n### DINOv1 was cool. DINOv2 made waves. But **DINOv3**?\n\nThat’s Meta’s attempt to build a visual foundation model that learns everything it needs to know about an image… without a single label. And it actually works.\n\n> My new book on Model Context Protocol is live now\n\n[Model Context Protocol: Advanced AI Agents for Beginners (Generative AI books) ------------------------------------------------------------------------------ ### Amazon.com: Model Context Protocol: Advanced AI Agents for Beginners (Generative AI books) eBook : Gupta, Mehul, Sen… www.amazon.com](https://www.amazon.com/gp/product/B0FCCF348X?source=post_page-----cf5ffc30a221---------------------------------------)\n\nHere’s what makes DINOv3 a real shift.\n\nPress enter or click to view image in full size\n\n![Image 16](https://miro.medium.com/v2/resize:fit:700/1*onlksvu_Acd1uDloFOfm8Q.png)\n\nNo Labels. No Fine-Tuning. Still SOTA.\n--------------------------------------\n\nLet’s start with what it does best. DINOv3 doesn’t just learn global stuff, like “this is a cat” vs. “this is a toaster.”\n\n> It learns **dense features**. Meaning: every patch, every region in the image, carries something semantically meaningful.\n\nAnd that’s massive for stuff like segmentation, object tracking, depth estimation, 3D matching. All without fine-tuning. You just freeze the model and use the outputs.\n\nThis is the first SSL model I’ve seen that actually _beats_ models like CLIP or SAM on dense tasks, despite those being trained with supervision or text labels.\n\n![Image 17](https://miro.medium.com/v2/resize:fit:673/1*ALycbb1scFHpMov-mFOJZA.png)\n\nBuilt at Scale: 7B Parameters, From Scratch\n-------------------------------------------\n\nPress enter or click to view image in full size\n\n![Image 18](https://miro.medium.com/v2/resize:fit:700/1*GGbw3IzE5uhcq4KnD11RPA.png)\n\nThe core model is a **7-billion parameter Vision Transformer** (ViT-7B). Not something you run casually on your laptop, but Meta did the work. They didn’t use JFT-300M or LAION or labels or web metadata. Just **raw images,**17 billion of them, scraped from Instagram.\n\nPress enter or click to view image in full size\n\n![Image 19](https://miro.medium.com/v2/resize:fit:700/1*Hjlr-PlRXobZgf65w6-tSw.png)\n\nAnd not randomly thrown together either. They curated the data using:\n\n> Hierarchical k-means clustering to ensure visual diversity\n> \n> \n> Retrieval-based sampling to get conceptually relevant samples\n> \n> \n> A little bit of ImageNet thrown in for balance\n\nSo this isn’t a “dump everything into the training bin” approach. It’s tuned, balanced, and large.\n\nPress enter or click to view image in full size\n\n![Image 20](https://miro.medium.com/v2/resize:fit:700/1*m6fmj8AUjG7pZryYp-i9tQ.png)\n\nDense Features Without Collapse,Gram Anchoring\n----------------------------------------------\n\nHere’s the thing with dense features. Train a model too long, especially a large one, and your patch-wise features start getting weird. Noisy. Over-smooth. Sometimes they just collapse.\n\nPress enter or click to view image in full size\n\n![Image 21](https://miro.medium.com/v2/resize:fit:700/1*lxVhWLTRBsWgSBvSkYk1jg.png)\n\n**_To stop this, Meta introduced something called Gram Anchoring._**\n\n### What’s Gram Anchoring?\n\nIt’s a new kind of loss function that **forces the structure of similarities between patch features to stay stable** during long training. Basically, the model compares its current patch similarities to those from an earlier, more consistent checkpoint. It doesn’t care if the features drift a little, as long as the _relationships_ between patches stay clean.\n\nGet Mehul Gupta’s stories in your inbox\n---------------------------------------\n\nJoin Medium for free to get updates from this writer.\n\nSubscribe\n\nSubscribe\n\nThis one trick fixes the feature degradation that hit DINOv2 and other SSL models. And it unlocks long-form training, even on 7B parameter behemoths.\n\nPress enter or click to view image in full size\n\n![Image 22](https://miro.medium.com/v2/resize:fit:700/1*_kvTpuo_LTb1Qn54Lnizog.png)\n\n**_Bonus_**: They also tried a **high-resolution version** of Gram Anchoring where the teacher uses bigger input images. That further smooths out patch inconsistencies.\n\nAdapted for High-Resolution Inputs\n----------------------------------\n\nPress enter or click to view image in full size\n\n![Image 23](https://miro.medium.com/v2/resize:fit:700/1*sI9liBX__fNAMspAr96-vA.png)\n\nMost models are trained on 224x224 or maybe 256x256 resolution. But then people throw 1024px images at them and expect sharp segmentation. Not gonna happen unless you adapt the model.\n\n> DINOv3 gets a **post-training high-resolution tuning phase**. They feed in crops at 512, 768, even higher, and adjust the model using Gram Anchoring. This makes the model generalize _upward_ in resolution.\n\nSo now you can throw 4K resolution satellite images, aerial maps, or dense street scenes at it, and it doesn’t fall apart. You still get usable features across the image.\n\nFrozen Backbone. Many Tasks. No Fine-Tuning.\n--------------------------------------------\n\n**_Once trained, DINOv3 just… works. You don’t fine-tune._** You don’t add heads. You run it, freeze the outputs, and apply simple linear layers or KNN or light clustering. That’s it.\n\nHere are the kinds of tasks where DINOv3 performs absurdly well:\n\n*   **Semantic Segmentation:**ADE20k, Cityscapes, Pascal VOC, all handled with just linear probes\n*   **Monocular Depth Estimation****:**On datasets like NYUv2 and KITTI\n*   **3D Correspondence Matching:**Multi-view consistency stays sharp, which helps in geometry-heavy stuff\n*   **Object Tracking and Video Understanding:**Patch-wise features stay stable frame-to-frame\n\n> In all of these, it outperforms DINOv2, CLIP-style models (like SigLIP), and even the recent AM-RADIO which distills SAM + CLIP + DINOv2 into one.\n\nDistillation Done Right\n-----------------------\n\nPress enter or click to view image in full size\n\n![Image 24](https://miro.medium.com/v2/resize:fit:700/1*24a5T9ZA9F2DGgBvcKF4UQ.png)\n\nThe full 7B model is great if you’ve got juice. But Meta also distilled it down into smaller models that are actually usable:\n\n*   ViT-S (21M params)\n*   ViT-B (86M)\n*   ViT-L (300M)\n*   ViT-H+ (800M)\n\nThey even built a **multi-student distillation setup** that lets them train all these students in parallel, reusing teacher outputs across GPUs. Smart use of compute. These smaller models retain most of the 7B’s power, especially on dense tasks. And they run fast.\n\nAdd Text If You Want To\n-----------------------\n\nThe model itself is purely visual. But if you want zero-shot classification or retrieval, you can bolt on a **text encoder**. They use a contrastive objective (like CLIP) to align pooled visual + patch features with text, while keeping the vision backbone frozen.\n\n> That gives you global + local alignment, so you don’t just match “cat” but also “striped tail” or “whiskers” at the patch level.\n\nWhy This Model Actually Matters\n-------------------------------\n\nHere’s why DINOv3 isn’t just another bump on the benchmark charts:\n\n*   **It breaks the need for supervision.** No labels, no alt-text, no human-in-the-loop. Just raw pixels.\n*   **It handles dense and global tasks with equal strength.** Most models pick a side. This doesn’t.\n*   **It scales.** Training doesn’t collapse at 7B. Feature quality doesn’t degrade over time.\n*   **It generalizes.** Works on natural images, aerial views, medical scans, biology datasets, without task-specific finetuning.\n\nIt’s not perfect. You’ll still need some GPU muscle. But for anyone serious about _building_ models, not just using other people’s APIs, DINOv3 is a landmark.\n\nIf you want to mess with self-supervised vision, or build something that runs well without being fragile to domain shifts, start looking at DINOv3. It’s not just another ViT, it’s what ViT looks like when it actually understands space.\n\n[AI](http://medium.com/tag/ai?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Technology](http://medium.com/tag/technology?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Machine Learning](http://medium.com/tag/machine-learning?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Data Science](http://medium.com/tag/data-science?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Deep Learning](http://medium.com/tag/deep-learning?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-in-your-pocket%2Fcf5ffc30a221&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&user=Mehul+Gupta&userId=d4ec90760d5b&source=---footer_actions--cf5ffc30a221---------------------clap_footer------------------)\n\n115\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-in-your-pocket%2Fcf5ffc30a221&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&user=Mehul+Gupta&userId=d4ec90760d5b&source=---footer_actions--cf5ffc30a221---------------------clap_footer------------------)\n\n115\n\n3\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcf5ffc30a221&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&source=---footer_actions--cf5ffc30a221---------------------bookmark_footer------------------)\n\n[![Image 25: Data Science in Your Pocket](https://miro.medium.com/v2/resize:fill:48:48/1*azLPGT6SA58kykLPlca3TQ.jpeg)](https://medium.com/data-science-in-your-pocket?source=post_page---post_publication_info--cf5ffc30a221---------------------------------------)\n\n[![Image 26: Data Science in Your Pocket](https://miro.medium.com/v2/resize:fill:64:64/1*azLPGT6SA58kykLPlca3TQ.jpeg)](https://medium.com/data-science-in-your-pocket?source=post_page---post_publication_info--cf5ffc30a221---------------------------------------)\n\nFollow\n\n[Published in Data Science in Your Pocket ----------------------------------------](https://medium.com/data-science-in-your-pocket?source=post_page---post_publication_info--cf5ffc30a221---------------------------------------)\n\n[6.3K followers](http://medium.com/data-science-in-your-pocket/followers?source=post_page---post_publication_info--cf5ffc30a221---------------------------------------)\n\n·[Last published 1 day ago](http://medium.com/data-science-in-your-pocket/fine-tuning-microsofts-phi-4-instruct-with-lora-scaling-inference-with-vllm-4b1f6fdb8b34?source=post_page---post_publication_info--cf5ffc30a221---------------------------------------)\n\nWe are on Youtube: [https://www.youtube.com/channel/UCQoNosQTIxiMTL9C-gvFdjA](https://www.youtube.com/channel/UCQoNosQTIxiMTL9C-gvFdjA)\n\nFollow\n\n[![Image 27: Mehul Gupta](https://miro.medium.com/v2/resize:fill:48:48/1*vyvhK_h4zA05mg_Y-n2qBA.jpeg)](http://medium.com/@mehulgupta_7991?source=post_page---post_author_info--cf5ffc30a221---------------------------------------)\n\n[![Image 28: Mehul Gupta](https://miro.medium.com/v2/resize:fill:64:64/1*vyvhK_h4zA05mg_Y-n2qBA.jpeg)](http://medium.com/@mehulgupta_7991?source=post_page---post_author_info--cf5ffc30a221---------------------------------------)\n\nFollow\n\n[Written by Mehul Gupta ----------------------](http://medium.com/@mehulgupta_7991?source=post_page---post_author_info--cf5ffc30a221---------------------------------------)\n\n[17.3K followers](http://medium.com/@mehulgupta_7991/followers?source=post_page---post_author_info--cf5ffc30a221---------------------------------------)\n\n·[37 following](http://medium.com/@mehulgupta_7991/following?source=post_page---post_author_info--cf5ffc30a221---------------------------------------)\n\nLinkedin : [https://www.linkedin.com/in/mehulgupta7991/](https://www.linkedin.com/in/mehulgupta7991/)\n\nFollow\n\nResponses (3)\n-------------\n\n[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--cf5ffc30a221---------------------------------------)\n\n![Image 29: Alberto Scocco](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)\n\nWrite a response\n\n[What are your thoughts?](http://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fmeta-dino-v3-the-ultimate-vision-ai-for-every-image-task-cf5ffc30a221&source=---post_responses--cf5ffc30a221---------------------respond_sidebar------------------)\n\nCancel\n\nRespond\n\n[![Image 30: craig parsy](https://miro.medium.com/v2/resize:fill:32:32/0*MF8V-7dO-e6g2ZXD)](http://medium.com/@parseyc?source=post_page---post_responses--cf5ffc30a221----0-----------------------------------)\n\n[craig parsy](http://medium.com/@parseyc?source=post_page---post_responses--cf5ffc30a221----0-----------------------------------)\n\n[2 days ago](http://medium.com/@parseyc/so-if-it-doesnt-take-labels-in-training-how-does-it-take-labels-in-deployment-thats-the-beauty-of-ffe99cfdb1ab?source=post_page---post_responses--cf5ffc30a221----0-----------------------------------)\n\nSo if it doesnt take labels in training how does it take labels in deployment thats the beauty of say a yolo model besides some cool depth maybe some segementation am i missing something or is every article about dino written by someone who never tried to put it in production or train it?\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fffe99cfdb1ab&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40parseyc%2Fso-if-it-doesnt-take-labels-in-training-how-does-it-take-labels-in-deployment-thats-the-beauty-of-ffe99cfdb1ab&user=craig+parsy&userId=82e1426d1c2c&source=---post_responses--ffe99cfdb1ab----0-----------------respond_sidebar------------------)\n\nReply\n\n[![Image 31: Alberto Scocco](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)](http://medium.com/@p.castellini?source=post_page---post_responses--cf5ffc30a221----1-----------------------------------)\n\n[Alberto Scocco](http://medium.com/@p.castellini?source=post_page---post_responses--cf5ffc30a221----1-----------------------------------)\n\n[4 days ago(edited)](http://medium.com/@p.castellini/really-interesting-thank-you-96e9a6e17f51?source=post_page---post_responses--cf5ffc30a221----1-----------------------------------)\n\nReally interesting, thank you!\n\nI have two questions for you.\n\n- Does it work only with single images, or it processes videos gathering and relating frames?\n\n- I was wishing a kind of pose detection tool (eg human keypoints), but I haven't found it in the…more\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F96e9a6e17f51&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40p.castellini%2Freally-interesting-thank-you-96e9a6e17f51&user=Alberto+Scocco&userId=461251da4878&source=---post_responses--96e9a6e17f51----1-----------------respond_sidebar------------------)\n\nReply\n\n[![Image 32: Arturo Jasso](https://miro.medium.com/v2/resize:fill:32:32/0*NTLWdfqMjsCHwMtN)](http://medium.com/@ep104000?source=post_page---post_responses--cf5ffc30a221----2-----------------------------------)\n\n[Arturo Jasso](http://medium.com/@ep104000?source=post_page---post_responses--cf5ffc30a221----2-----------------------------------)\n\n[6 days ago](http://medium.com/@ep104000/great-intro-to-dino-1cd15ea5d361?source=post_page---post_responses--cf5ffc30a221----2-----------------------------------)\n\nGreat intro to DINO!\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1cd15ea5d361&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40ep104000%2Fgreat-intro-to-dino-1cd15ea5d361&user=Arturo+Jasso&userId=2911799f9321&source=---post_responses--1cd15ea5d361----2-----------------respond_sidebar------------------)\n\nReply\n\nMore from Mehul Gupta and Data Science in Your Pocket\n-----------------------------------------------------\n\n![Image 33: What is Google Nano Banana? Google’s Secret AI for Images](https://miro.medium.com/v2/resize:fit:679/format:webp/0*S7GNMS82M4AAr7ph)\n\n[![Image 34: Data Science in Your Pocket](https://miro.medium.com/v2/resize:fill:20:20/1*azLPGT6SA58kykLPlca3TQ.jpeg)](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--cf5ffc30a221----0---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nIn\n\n[Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--cf5ffc30a221----0---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nby\n\n[Mehul Gupta](http://medium.com/@mehulgupta_7991?source=post_page---author_recirc--cf5ffc30a221----0---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n[What is Google Nano Banana? Google’s Secret AI for Images --------------------------------------------------------- ### Google is secretly testing Nano Banana across platforms](http://medium.com/data-science-in-your-pocket/what-is-google-nano-banana-googles-secret-ai-for-images-2958f9ab11e3?source=post_page---author_recirc--cf5ffc30a221----0---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n6d ago\n\n[89 15](http://medium.com/data-science-in-your-pocket/what-is-google-nano-banana-googles-secret-ai-for-images-2958f9ab11e3?source=post_page---author_recirc--cf5ffc30a221----0---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2958f9ab11e3&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fwhat-is-google-nano-banana-googles-secret-ai-for-images-2958f9ab11e3&source=---author_recirc--cf5ffc30a221----0-----------------bookmark_preview----debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n![Image 35: Dijkstra Defeated : New Fastest Shortest Path Algorithm explained](https://miro.medium.com/v2/resize:fit:679/format:webp/1*72aUCdwXmOXrbZX-yJutIw.png)\n\n[![Image 36: Data Science in Your Pocket](https://miro.medium.com/v2/resize:fill:20:20/1*azLPGT6SA58kykLPlca3TQ.jpeg)](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--cf5ffc30a221----1---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nIn\n\n[Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--cf5ffc30a221----1---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nby\n\n[Mehul Gupta](http://medium.com/@mehulgupta_7991?source=post_page---author_recirc--cf5ffc30a221----1---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n[Dijkstra Defeated: New Fastest Shortest Path Algorithm explained ---------------------------------------------------------------- ### Breaking the Sorting Barrier for Directed Single-Source Shortest Paths explained with example](http://medium.com/data-science-in-your-pocket/dijkstra-defeated-new-fastest-shortest-path-algorithm-explained-4075b000353a?source=post_page---author_recirc--cf5ffc30a221----1---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nAug 17\n\n[116 2](http://medium.com/data-science-in-your-pocket/dijkstra-defeated-new-fastest-shortest-path-algorithm-explained-4075b000353a?source=post_page---author_recirc--cf5ffc30a221----1---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4075b000353a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fdijkstra-defeated-new-fastest-shortest-path-algorithm-explained-4075b000353a&source=---author_recirc--cf5ffc30a221----1-----------------bookmark_preview----debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n![Image 37: Google LangExtract : AI powered Information Extraction using Gemini](https://miro.medium.com/v2/resize:fit:679/format:webp/0*Rt1zeFRuM5QJrdN4)\n\n[![Image 38: Data Science in Your Pocket](https://miro.medium.com/v2/resize:fill:20:20/1*azLPGT6SA58kykLPlca3TQ.jpeg)](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--cf5ffc30a221----2---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nIn\n\n[Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--cf5ffc30a221----2---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nby\n\n[Mehul Gupta](http://medium.com/@mehulgupta_7991?source=post_page---author_recirc--cf5ffc30a221----2---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n[Google LangExtract: AI powered Information Extraction using Gemini ------------------------------------------------------------------ ### How to use Google LangExtract?](http://medium.com/data-science-in-your-pocket/google-langextract-ai-powered-information-extraction-using-gemini-290cd4ab1b2c?source=post_page---author_recirc--cf5ffc30a221----2---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nAug 12\n\n[256 3](http://medium.com/data-science-in-your-pocket/google-langextract-ai-powered-information-extraction-using-gemini-290cd4ab1b2c?source=post_page---author_recirc--cf5ffc30a221----2---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F290cd4ab1b2c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fgoogle-langextract-ai-powered-information-extraction-using-gemini-290cd4ab1b2c&source=---author_recirc--cf5ffc30a221----2-----------------bookmark_preview----debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n![Image 39: GLM 4.5 : The best Open-Source AI model, beats Kimi-K2, Qwen3](https://miro.medium.com/v2/resize:fit:679/format:webp/0*WmTSF7nwGC1iExyV)\n\n[![Image 40: Data Science in Your Pocket](https://miro.medium.com/v2/resize:fill:20:20/1*azLPGT6SA58kykLPlca3TQ.jpeg)](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--cf5ffc30a221----3---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nIn\n\n[Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--cf5ffc30a221----3---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nby\n\n[Mehul Gupta](http://medium.com/@mehulgupta_7991?source=post_page---author_recirc--cf5ffc30a221----3---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n[GLM 4.5: The best Open-Source AI model, beats Kimi-K2, Qwen3 ------------------------------------------------------------ ### How to use GLM 4.5 for free?](http://medium.com/data-science-in-your-pocket/glm-4-5-the-best-open-source-ai-model-beats-kimi-k2-qwen3-b56a5df2ec34?source=post_page---author_recirc--cf5ffc30a221----3---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\nJul 28\n\n[416 6](http://medium.com/data-science-in-your-pocket/glm-4-5-the-best-open-source-ai-model-beats-kimi-k2-qwen3-b56a5df2ec34?source=post_page---author_recirc--cf5ffc30a221----3---------------------debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb56a5df2ec34&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fglm-4-5-the-best-open-source-ai-model-beats-kimi-k2-qwen3-b56a5df2ec34&source=---author_recirc--cf5ffc30a221----3-----------------bookmark_preview----debcdf53_bb0f_49e4_a353_43a698ddf6c8--------------)\n\n[See all from Mehul Gupta](http://medium.com/@mehulgupta_7991?source=post_page---author_recirc--cf5ffc30a221---------------------------------------)\n\n[See all from Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--cf5ffc30a221---------------------------------------)\n\nRecommended from Medium\n-----------------------\n\n![Image 41: I Finally Understood “Attention is All You Need” After So Long. Here’s How I Did It.](https://miro.medium.com/v2/resize:fit:679/format:webp/1*kL3ilZSFElPb20j9mEO-SQ.jpeg)\n\n[![Image 42: Artificial Intelligence in Plain English](https://miro.medium.com/v2/resize:fill:20:20/1*9zAmnK08gUCmZX7q0McVKw@2x.png)](https://medium.com/ai-in-plain-english?source=post_page---read_next_recirc--cf5ffc30a221----0---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nIn\n\n[Artificial Intelligence in Plain English](https://medium.com/ai-in-plain-english?source=post_page---read_next_recirc--cf5ffc30a221----0---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nby\n\n[Olubusolami Sogunle](http://medium.com/@busolasogunle?source=post_page---read_next_recirc--cf5ffc30a221----0---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[I Finally Understood “Attention is All You Need” After So Long. Here’s How I Did It. ------------------------------------------------------------------------------------ ### It’s been almost 2 years since I first encountered the “Attention is all you need” paper by Vaswani et al. (2017). I’ve mentioned it…](http://medium.com/ai-in-plain-english/i-finally-understood-attention-is-all-you-need-after-so-long-heres-how-i-did-it-263b46273f9f?source=post_page---read_next_recirc--cf5ffc30a221----0---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nJul 12\n\n[420 6](http://medium.com/ai-in-plain-english/i-finally-understood-attention-is-all-you-need-after-so-long-heres-how-i-did-it-263b46273f9f?source=post_page---read_next_recirc--cf5ffc30a221----0---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F263b46273f9f&operation=register&redirect=https%3A%2F%2Fai.plainenglish.io%2Fi-finally-understood-attention-is-all-you-need-after-so-long-heres-how-i-did-it-263b46273f9f&source=---read_next_recirc--cf5ffc30a221----0-----------------bookmark_preview----1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n![Image 43: DINOv3 Just Changed Computer Vision Forever](https://miro.medium.com/v2/resize:fit:679/format:webp/1*zDJXtMgCExJtRv2QXg0lsg.png)\n\n[![Image 44: Towards Deep Learning](https://miro.medium.com/v2/resize:fill:20:20/1*LF1EF4T2UFrpxYubZ7r_7g.png)](https://medium.com/towards-deep-learning?source=post_page---read_next_recirc--cf5ffc30a221----1---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nIn\n\n[Towards Deep Learning](https://medium.com/towards-deep-learning?source=post_page---read_next_recirc--cf5ffc30a221----1---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nby\n\n[Sumit Pandey](http://medium.com/@sumit.ai?source=post_page---read_next_recirc--cf5ffc30a221----1---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[DINOv3 Just Changed Computer Vision Forever ------------------------------------------- ### I’ve been waiting for this one. Meta’s DINOv3 feels like the moment self-supervised vision finally crosses from great features to a single…](http://medium.com/towards-deep-learning/dinov3-just-changed-computer-vision-forever-961748538fbf?source=post_page---read_next_recirc--cf5ffc30a221----1---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nAug 14\n\n[82 4](http://medium.com/towards-deep-learning/dinov3-just-changed-computer-vision-forever-961748538fbf?source=post_page---read_next_recirc--cf5ffc30a221----1---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F961748538fbf&operation=register&redirect=https%3A%2F%2Fwww.towardsdeeplearning.com%2Fdinov3-just-changed-computer-vision-forever-961748538fbf&source=---read_next_recirc--cf5ffc30a221----1-----------------bookmark_preview----1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n![Image 45: Google Gemma3 270M : The best Smallest LLM for everything](https://miro.medium.com/v2/resize:fit:679/format:webp/0*hhgagpsGouRbI3Fv)\n\n[![Image 46: Data Science in Your Pocket](https://miro.medium.com/v2/resize:fill:20:20/1*azLPGT6SA58kykLPlca3TQ.jpeg)](https://medium.com/data-science-in-your-pocket?source=post_page---read_next_recirc--cf5ffc30a221----0---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nIn\n\n[Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---read_next_recirc--cf5ffc30a221----0---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nby\n\n[Mehul Gupta](http://medium.com/@mehulgupta_7991?source=post_page---read_next_recirc--cf5ffc30a221----0---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[Google Gemma3 270M: The best Smallest LLM for everything -------------------------------------------------------- ### How to use Google Gemma3 270M for free?](http://medium.com/data-science-in-your-pocket/google-gemma3-270m-the-best-smallest-llm-for-everything-efcf927a74be?source=post_page---read_next_recirc--cf5ffc30a221----0---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nAug 15\n\n[350 5](http://medium.com/data-science-in-your-pocket/google-gemma3-270m-the-best-smallest-llm-for-everything-efcf927a74be?source=post_page---read_next_recirc--cf5ffc30a221----0---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fefcf927a74be&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fgoogle-gemma3-270m-the-best-smallest-llm-for-everything-efcf927a74be&source=---read_next_recirc--cf5ffc30a221----0-----------------bookmark_preview----1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n![Image 47: Google’s New LLM Runs on Just 0.5 GB RAM — Here’s How to Fine-Tune It Locally”](https://miro.medium.com/v2/resize:fit:679/format:webp/1*6XvWNBI_WnBLDuPw1WLPJA.png)\n\n[![Image 48: Coding Nexus](https://miro.medium.com/v2/resize:fill:20:20/1*KCZtO6-wFqmTaMmbTMicbw.png)](https://medium.com/coding-nexus?source=post_page---read_next_recirc--cf5ffc30a221----1---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nIn\n\n[Coding Nexus](https://medium.com/coding-nexus?source=post_page---read_next_recirc--cf5ffc30a221----1---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nby\n\n[Civil Learning](http://medium.com/@civillearning?source=post_page---read_next_recirc--cf5ffc30a221----1---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[Google’s New LLM Runs on Just 0.5 GB RAM — Here’s How to Fine-Tune It Locally” ------------------------------------------------------------------------------ ### A few days ago, Google quietly released a little AI model called Gemma 3 270M.](http://medium.com/coding-nexus/googles-new-llm-runs-on-just-0-5-gb-ram-here-s-how-to-fine-tune-it-locally-ab910fa39732?source=post_page---read_next_recirc--cf5ffc30a221----1---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nAug 16\n\n[1.2K 18](http://medium.com/coding-nexus/googles-new-llm-runs-on-just-0-5-gb-ram-here-s-how-to-fine-tune-it-locally-ab910fa39732?source=post_page---read_next_recirc--cf5ffc30a221----1---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fab910fa39732&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoding-nexus%2Fgoogles-new-llm-runs-on-just-0-5-gb-ram-here-s-how-to-fine-tune-it-locally-ab910fa39732&source=---read_next_recirc--cf5ffc30a221----1-----------------bookmark_preview----1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n![Image 49: DINOv3: a frozen universal vision backbone you can actually ship](https://miro.medium.com/v2/resize:fit:679/format:webp/1*5wbrcmV-GzhWD-QnZ32xxg.png)\n\n[![Image 50: Pankaj](https://miro.medium.com/v2/resize:fill:20:20/1*xFkR0dRBHLWuGKwsCARv8g.png)](http://medium.com/@pankaj_pandey?source=post_page---read_next_recirc--cf5ffc30a221----2---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[Pankaj](http://medium.com/@pankaj_pandey?source=post_page---read_next_recirc--cf5ffc30a221----2---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[DINOv3: a frozen universal vision backbone you can actually ship ---------------------------------------------------------------- ### DINOv3 is a self-supervised (no labels) vision backbone family whose frozen features set state-of-the-art results on dense prediction, so…](http://medium.com/@pankaj_pandey/dinov3-a-frozen-universal-vision-backbone-you-can-actually-ship-16f5d285c38d?source=post_page---read_next_recirc--cf5ffc30a221----2---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nAug 17\n\n[51](http://medium.com/@pankaj_pandey/dinov3-a-frozen-universal-vision-backbone-you-can-actually-ship-16f5d285c38d?source=post_page---read_next_recirc--cf5ffc30a221----2---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16f5d285c38d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40pankaj_pandey%2Fdinov3-a-frozen-universal-vision-backbone-you-can-actually-ship-16f5d285c38d&source=---read_next_recirc--cf5ffc30a221----2-----------------bookmark_preview----1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n![Image 51: The Python Tool I Built in a Weekend That Now Pays My Rent](https://miro.medium.com/v2/resize:fit:679/format:webp/1*uqWjBh7BUL2Wa9SFFCBBAg.png)\n\n[![Image 52: Python in Plain English](https://miro.medium.com/v2/resize:fill:20:20/1*VA3oGfprJgj5fRsTjXp6fA@2x.png)](https://medium.com/python-in-plain-english?source=post_page---read_next_recirc--cf5ffc30a221----3---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nIn\n\n[Python in Plain English](https://medium.com/python-in-plain-english?source=post_page---read_next_recirc--cf5ffc30a221----3---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nby\n\n[Suleman Safdar](http://medium.com/@SulemanSafdar?source=post_page---read_next_recirc--cf5ffc30a221----3---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[The Python Tool I Built in a Weekend That Now Pays My Rent ---------------------------------------------------------- ### How I turned a tiny automation script into a paid product using libraries, clean OOP, and a little C++ speed where it mattered](http://medium.com/python-in-plain-english/the-python-tool-i-built-in-a-weekend-that-now-pays-my-rent-bbc5b81a0bdd?source=post_page---read_next_recirc--cf5ffc30a221----3---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\nAug 12\n\n[2.4K 40](http://medium.com/python-in-plain-english/the-python-tool-i-built-in-a-weekend-that-now-pays-my-rent-bbc5b81a0bdd?source=post_page---read_next_recirc--cf5ffc30a221----3---------------------1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[](http://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbbc5b81a0bdd&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2Fthe-python-tool-i-built-in-a-weekend-that-now-pays-my-rent-bbc5b81a0bdd&source=---read_next_recirc--cf5ffc30a221----3-----------------bookmark_preview----1418a768_d9f7_49b2_881e_53248045e9b1--------------)\n\n[See more recommendations](http://medium.com/?source=post_page---read_next_recirc--cf5ffc30a221---------------------------------------)\n\n[Help](https://help.medium.com/hc/en-us?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Status](https://medium.statuspage.io/?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[About](http://medium.com/about?autoplay=1&source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Careers](http://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Press](mailto:pressinquiries@medium.com)\n\n[Blog](https://blog.medium.com/?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cf5ffc30a221---------------------------------------)\n\n[Text to speech](https://speechify.com/medium?source=post_page-----cf5ffc30a221---------------------------------------)\n"
        }
      }
    ]
  },
  "connections": {
    "Fetch Medium HTML": {
      "main": [
        [
          {
            "node": "Parse Reader Markdown",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When executed by another node": {
      "main": [
        [
          {
            "node": "Fetch Medium HTML",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Member-only?": {
      "main": [
        [
          {
            "node": "Log (member-only)",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenAI Chat (JSON)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Log (member-only)": {
      "main": [
        [
          {
            "node": "Shape Output (skip)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat (JSON)": {
      "main": [
        [
          {
            "node": "Parse OpenAI JSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse OpenAI JSON": {
      "main": [
        [
          {
            "node": "Shape Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Reader Markdown": {
      "main": [
        [
          {
            "node": "Member-only?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "9cdcc3b2-c256-4a9c-958d-ccebfa76ff79",
  "meta": {
    "instanceId": "a396a459e20e70dadf88b2d8f204762d2d80680fe1414733547fa53f595d718e"
  },
  "id": "KRCc0Jm59F6dd23J",
  "tags": []
}